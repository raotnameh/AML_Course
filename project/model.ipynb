{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading the dataset\n",
      "--------------------Loading dataset--------------------\n",
      "Source:  (5000, 32, 32, 3) (5000,)\n",
      "Target:  (54000, 32, 32, 3)\n",
      "--------------------Loading dataset--------------------\n",
      "Gallery:  (54000, 32, 32, 3) (54000,)\n",
      "Query:  (1000, 32, 32, 3) (1000,)\n",
      "Data loading finished\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from data.data_loader import *\n",
    "from model import *\n",
    "import torch.optim as optim\n",
    "\n",
    "batchSize = 2\n",
    "\n",
    "print(\"Loading the dataset\")\n",
    "Source_x, Source_y, Target_x = prepare_Data(data_dir, True)\n",
    "Gallery_x, Query_x = prepare_Data(data_dir, False)\n",
    "label_Similarity = csr_matrix(scipy.io.loadmat(\"data/cifar10/cifar10_Similarity.mat\")['label_Similarity']).todense()\n",
    "print(\"Data loading finished\")\n",
    "\n",
    "source = torch.utils.data.DataLoader([(Source_x[i], Source_y[i]) for i in range(len(Source_x))],batch_size=batchSize)\n",
    "target = torch.utils.data.DataLoader(Target_x,batch_size=batchSize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggModel=models.vgg16_bn(pretrained=True)\n",
    "# vggModel.children"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "net1, net2 = [], []\n",
    "for i in vggModel.children():\n",
    "    for r, i in enumerate(i.children()):\n",
    "        if r <=23: net1.append(i)\n",
    "        elif r<= 32: net2.append(i)\n",
    "    break\n",
    "net1, net2  = nn.Sequential(*net1), nn.Sequential(*net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intranorm(features,n_book):\n",
    "    x = features.split(n_book,1)\n",
    "    \n",
    "    for b in range(n_book):\n",
    "        if b==0: dummy = F.normalize(x[b],1)\n",
    "        else:\n",
    "            dummy = torch.cat((dummy,F.normalize(x[b],1)),1)\n",
    "    return dummy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_(inp):\n",
    "     for i in inp:\n",
    "            print(f\"shape is: {i.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softassignment_(nn.Module):\n",
    "    def __init__(self,len_code, n_book, intn_word):\n",
    "        super(softassignment_,self).__init__()\n",
    "        self.Z = nn.Linear(len_code * n_book,intn_word, bias=False)\n",
    "\n",
    "    def forward(self,Z,features,n_book,alpha,):\n",
    "        z_ = Z.split(n_book,1)\n",
    "        x_ = features.split(n_book,1)\n",
    "\n",
    "        for i in range(n_book):\n",
    "            size_z = z_[i].shape[0] # number of codewords\n",
    "            size_x = x_[i].shape[0] # batch size\n",
    "            xx = x_[i].unsqueeze(-1)\n",
    "            xx = xx.repeat(1,1,size_z)\n",
    "            zz = z_[i].unsqueeze(-1)\n",
    "            zz = zz.repeat(1,1,size_x).T\n",
    "\n",
    "            diff = 1 - torch.sum(torch.mul(xx,zz), 1) # 32,16\n",
    "            softmax_diff = F.softmax(diff*(-alpha),1) #32,16\n",
    "            soft_des_temp = torch.matmul(softmax_diff,z_[i]) # 32,12\n",
    "            if i == 0: descriptor = soft_des_temp\n",
    "            else: descriptor = torch.cat((descriptor,soft_des_temp),1)\n",
    "\n",
    "        return intranorm(descriptor,n_book) # 32,144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_(nn.Module):\n",
    "    def __init__(self,n_CLASSES, len_code, n_book,):\n",
    "        super(classifier_,self).__init__()\n",
    "        self.prototypes = nn.Linear(len_code * n_book, n_CLASSES, bias=False) #[]\n",
    "#         for i in range(n_book):\n",
    "#             self.prototypes.append(nn.init.xavier_normal_(torch.empty(n_CLASSES, len_code * n_book)))\n",
    "        \n",
    "    def forward(self, x,c):\n",
    "        x_ = x.split(n_book,1)\n",
    "        c_ = c.split(n_book,0)\n",
    "#         shape_(x_[0])\n",
    "#         shape_(c_[0])\n",
    "        for i in range(n_book):\n",
    "            sub_res = torch.matmul(x_[i], c_[i]).unsqueeze(-1)\n",
    "            if i == 0: res = sub_res\n",
    "            else: res = torch.cat((res,sub_res),2)\n",
    "        \n",
    "        return torch.sum(res, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "class features_(nn.Module):\n",
    "    def __init__(self, net1, net2):\n",
    "        super(features_,self).__init__()\n",
    "        \n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        self.gavgp = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear = nn.Linear(768, len_code*n_book)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.net1(x) # shape: torch.Size([32, 3, 32,32])>torch.Size([32, 3, 4, 4])\n",
    "        x_branch = self.gavgp(x)\n",
    "        x = self.net2(x) # shape: torch.Size([32, 3, 4, 4])> torch.Size([32, 3, 4, 4])\n",
    "        x = self.gavgp(x)\n",
    "        \n",
    "        x = torch.cat((x,x_branch),1)\n",
    "        \n",
    "        return self.linear(x.view(-1,768))\n",
    "    \n",
    "# x = torch.randn(32, 3, 32, 32, device='cpu')\n",
    "# model = features_(net1, net2)\n",
    "# out = model(x)# model\n",
    "# out.shape, out.split(12,1)[0].shape, model.Z.shape, model.prototypes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "model = features_(net1, net2).to(device)\n",
    "classifier = classifier_(n_CLASSES, len_code, n_book).to(device)\n",
    "softassignment = softassignment_(len_code, n_book, intn_word).to(device)\n",
    "\n",
    "# optimizer\n",
    "class_optim = optim.Adam(classifier.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "model_optim = optim.Adam(model.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "soft_optim = optim.Adam(softassignment.parameters(),lr=0.0002,betas=(0.5,0.999))\n",
    "\n",
    "prototypes = intranorm(classifier.prototypes.state_dict()['weight'], n_book).to(device)\n",
    "Z = intranorm(softassignment.Z.state_dict()['weight'], n_book).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape is: torch.Size([2, 32, 32, 3])\n",
      "shape is: torch.Size([2])\n",
      "shape is: torch.Size([2, 32, 32, 3])\n",
      "tensor(0.3484, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "target_ = iter(target)\n",
    "for epoch in range(1):\n",
    "    for batch in source:\n",
    "        x, y = batch\n",
    "        x = torch.tensor(data_augmentation(x)).to(device)\n",
    "        try: \n",
    "            xu = next(target_)\n",
    "            xu = torch.tensor(data_augmentation(xu)).to(device)\n",
    "        except:\n",
    "            target_ = iter(target)\n",
    "            xu = next(target_)\n",
    "            xu = torch.tensor(data_augmentation(xu)).to(device)\n",
    "        shape_([x,y,xu])\n",
    "        \n",
    "        \n",
    "        y_ = y.to(device)\n",
    "        y=torch.eye(numClasses)[y]\n",
    "        ymat=torch.matmul(y,y.T)\n",
    "        ymat/=torch.sum(ymat,axis=1,keepdims=True)\n",
    "        ymat = ymat.to(device)\n",
    "#         y = y.to(device)\n",
    "        \n",
    "        \n",
    "        features = intranorm(model(x.permute(0,3,1,2)), n_book)\n",
    "        quanta = softassignment(Z,features,n_book,alpha)\n",
    "        logits = classifier(features, prototypes.T)\n",
    "        \n",
    "        hash_loss = NPQLoss(ymat,features, quanta,n_book)\n",
    "        print(hash_loss)\n",
    "        cls_loss = torch.nn.functional.cross_entropy(logits,y_)\n",
    "        entropy_loss = SMELoss(features * beta, prototypes * beta, n_book)\n",
    "        final_loss = hash_loss + lam_1*entropy_loss + lam_2*cls_loss \n",
    "        \n",
    "        break\n",
    "        optimizer.zero_grad()\n",
    "        final_loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softassignment(Z,features,n_book,alpha,):\n",
    "        z_ = Z.split(n_book,1)\n",
    "        x_ = features.split(n_book,1)\n",
    "        \n",
    "        for i in range(n_book):\n",
    "            size_z = z_[i].shape[0] # number of codewords\n",
    "            size_x = x_[i].shape[0] # batch size\n",
    "            xx = x_[i].unsqueeze(-1)\n",
    "            xx = xx.repeat(1,1,size_z)\n",
    "            zz = z_[i].unsqueeze(-1)\n",
    "            zz = zz.repeat(1,1,size_x).T\n",
    "            \n",
    "            diff = 1 - torch.sum(torch.mul(xx,zz), 1) # 32,16\n",
    "            softmax_diff = F.softmax(diff*(-alpha),1) #32,16\n",
    "            soft_des_temp = torch.matmul(softmax_diff,z_[i]) # 32,12\n",
    "            if i == 0: descriptor = soft_des_temp\n",
    "            else: descriptor = torch.cat((descriptor,soft_des_temp),1)\n",
    "            \n",
    "        return intranorm(descriptor,n_book) # 32,144"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
