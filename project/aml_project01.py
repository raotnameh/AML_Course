# -*- codig: utf-9 -*-
"""AML_Project01.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BSYR25A1ztAMjhymcmReH72EOfPnJrgz
"""
from model import *
import torch
from data.data_loader import *
import numpy as np 
batch_size=500
def cat_apcal(label_Similarity, IX, top_N):

    [_, numtest] = IX.shape

    apall = np.zeros(numtest)

    for i in range(numtest):
        y = IX[:, i]
        x = 0
        p = 0

        for j in range(1000):
            if label_Similarity[i, y[j]] == 1:
                x = x + 1
                p = p + float(x) / (j + 1)
        if p == 0:
            apall[i] = 0
        else:
            apall[i] = p / x

    mAP = np.mean(apall)

    return mAP

def find_PQ_Table(Z,n_codebook,gallery_x,query_x):
    
    D_Z = np.zeros((Z.shape[0], n_codebook), dtype=np.float32)

    gallery_x_split = np.split(gallery_x, n_codebook, 1) # 12, (54000,12)
    query_x_split = np.array_split(query_x, n_codebook,1)
    print(Z.shape,"Z Shape")  
    Z_split = np.split(Z.detach().numpy(),n_codebook, 1)
    D_Z_split = np.split(D_Z, n_codebook, 1)
    Dpq = np.zeros((query_x.shape[0], gallery_x.shape[0]), dtype=np.float32) # 1000,54000

    for i in range(query_x.shape[0]):
        for j in range(n_codebook):
            for k in range(Z.shape[0]):
                D_Z_split[j][k] =1-np.dot(query_x_split[j][i],Z_split[j][k])
            if j == 0:
                y = D_Z_split[j][gallery_x_split[j]]
            else:
                y = np.add(y, D_Z_split[j][gallery_x_split[j]])
        #print(y.shape)  # shape: 1000,12,1
        Dpq[i,:] = np.squeeze(y)
    return Dpq



def Image_Retrieval(model,Z_table,n_codebook,db_x,test_x,similarity,k):
 
  db_x=db_x[:1000]
  training_iteration=len(db_x)//batch_size
  
  for iteration in range(training_iteration-1):
   fet=[]
   for i in db_x[iteration*batch_size:iteration*batch_size+batch_size]:
    i=torch.Tensor(i).reshape(1,3,32,32)
    fet.append(i)
   b = torch.Tensor(batch_size,784)
   fet=torch.cat(fet, out=b)
   if iteration==0:
     feature_S=model.featureExtractor(fet).detach().numpy()
   else:
     feature_S=np.concatenate((feature_S,model.featureExtractor(fet).detach().numpy()),axis=0)  
   print(feature_S.shape)
  print(feature_S.sum())  
  index=(training_iteration+1)*batch_size - len(db_x)
   
   #for the last batch
  fet=[]
  for i in db_x[-1*batch_size:]:
    i=torch.Tensor(i).reshape(1,3,32,32)
    fet.append(i)
  b = torch.Tensor(batch_size,784)
  fet=torch.cat(fet, out=b)
  feature_S_last=model.featureExtractor(fet).detach().numpy()[-1*index:]
  #print(feature_S_last.shape)
  feature_S=np.concatenate((feature_S,feature_S_last),axis=0) 
  print(feature_S.shape)

  testing_iteration=len(test_x)//batch_size

  for iteration in range(testing_iteration-1):
   fet=[]
   for i in test_x[iteration*batch_size:iteration*batch_size+batch_size]:
    i=torch.Tensor(i).reshape(1,3,32,32)
    fet.append(i)
   b = torch.Tensor(batch_size,784)
   fet=torch.cat(fet, out=b)
   if iteration==0:
     feature_T=model.featureExtractor(fet).detach().numpy()
   else:
     feature_T=np.concatenate((feature_T,model.featureExtractor(fet).detach().numpy()),axis=0)
   print(feature_T.shape)
  index=(testing_iteration+1)*batch_size - len(test_x)

   #for the last batch
  fet=[]
  for i in test_x[-1*batch_size:]:
    i=torch.Tensor(i).reshape(1,3,32,32)
    fet.append(i)
  b = torch.Tensor(batch_size,784)
  fet=torch.cat(fet, out=b)
  feature_T_last=model.featureExtractor(fet).detach().numpy()[-1*index:]
  #print(feature_S_last.shape)
  feature_T=np.concatenate((feature_T,feature_T_last),axis=0)
  print(feature_T.shape)

  gallery_x=feature_S.astype(int)
  query_x=feature_T
  Sorted_PQ_table=np.argsort((find_PQ_Table(Z_table,n_codebook,gallery_x,query_x).T),axis=0)
  print(Sorted_PQ_table.shape)
  mean_average_precision=cat_apcal(similarity,Sorted_PQ_table,k)
  print(mean_average_precision)
  return mean_average_precision


