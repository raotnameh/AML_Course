{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available\n",
      "Loading the dataset\n",
      "--------------------Loading dataset--------------------\n",
      "Source:  (5000, 32, 32, 3) (5000,)\n",
      "Target:  (54000, 32, 32, 3)\n",
      "--------------------Loading dataset--------------------\n",
      "Gallery:  (54000, 32, 32, 3) (54000,)\n",
      "Query:  (1000, 32, 32, 3) (1000,)\n",
      "Data loading finished\n"
     ]
    }
   ],
   "source": [
    "from config import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from data.data_loader import *\n",
    "from model import *\n",
    "import torch.optim as optim\n",
    "from  RetrievalTest import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "batchSize = 500\n",
    "\n",
    "print(\"Loading the dataset\")\n",
    "Source_x, Source_y, Target_x = prepare_Data(data_dir, True)\n",
    "Gallery_x, Query_x = prepare_Data(data_dir, False)\n",
    "similarity = csr_matrix(scipy.io.loadmat(\"data/cifar10/cifar10_Similarity.mat\")['label_Similarity']).todense()\n",
    "\n",
    "print(\"Data loading finished\")\n",
    "\n",
    "gallery = torch.utils.data.DataLoader(Gallery_x,batch_size=1000)\n",
    "query = torch.utils.data.DataLoader(Query_x,batch_size=1000)\n",
    "\n",
    "source = torch.utils.data.DataLoader([(Source_x[i], Source_y[i]) for i in range(len(Source_x))],batch_size=batchSize, shuffle=True)\n",
    "target = torch.utils.data.DataLoader(Target_x,batch_size=batchSize,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vggModel=models.vgg16_bn(pretrained=True)\n",
    "# vggModel.children\n",
    "\n",
    "net1, net2 = [], []\n",
    "for i in vggModel.children():\n",
    "    for r, i in enumerate(i.children()):\n",
    "        if r <=23: net1.append(i)\n",
    "        elif r<= 32: net2.append(i)\n",
    "    break\n",
    "net1, net2  = nn.Sequential(*net1), nn.Sequential(*net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intranorm(features,n_book):\n",
    "    x = features.split(n_book,1)\n",
    "    \n",
    "    for b in range(n_book):\n",
    "        if b==0: dummy = F.normalize(x[b],1)\n",
    "        else:\n",
    "            dummy = torch.cat((dummy,F.normalize(x[b],1)),1)\n",
    "    return dummy\n",
    "\n",
    "def shape_(inp):\n",
    "     for i in inp:\n",
    "            print(f\"shape is: {i.shape}\")\n",
    "            \n",
    "def Indexing_(Z,des,numSeg):\n",
    "        Z = intranorm(Z,numSeg)\n",
    "        x = torch.split(des,numSeg,1)\n",
    "        y = torch.split(Z,numSeg,1)\n",
    "        for i in range(numSeg):\n",
    "            size_x = x[i].shape[0]\n",
    "            size_y = y[i].shape[0]\n",
    "            xx = x[i].unsqueeze(-1)\n",
    "\n",
    "            dummy = torch.tensor(1)\n",
    "            xx = xx.tile([1,1,size_y])\n",
    "            yy = y[i].unsqueeze(-1)\n",
    "            yy = yy.tile([1,1,size_x])\n",
    "            yy = yy.permute(2,1,0)\n",
    "            diff = torch.sum(torch.multiply(xx,yy),1)\n",
    "\n",
    "            arg = torch.argmax(diff,1)\n",
    "            max_idx = arg.reshape(-1,1)\n",
    "\n",
    "            if i == 0: quant_idx = max_idx\n",
    "            else: quant_idx = torch.cat((quant_idx,max_idx),1)\n",
    "\n",
    "        return quant_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class softassignment_(nn.Module):\n",
    "    def __init__(self,len_code, n_book, intn_word):\n",
    "        super(softassignment_,self).__init__()\n",
    "        self.Z = nn.Linear(len_code * n_book,intn_word, bias=False)\n",
    "\n",
    "    def forward(self,features,n_book,alpha,):\n",
    "        z_ = intranorm(self.Z.state_dict()['weight'], n_book).split(n_book,1)\n",
    "        x_ = features.split(n_book,1)\n",
    "\n",
    "        for i in range(n_book):\n",
    "            size_z = z_[i].shape[0] # number of codewords\n",
    "            size_x = x_[i].shape[0] # batch size\n",
    "            xx = x_[i].unsqueeze(-1)\n",
    "            xx = xx.repeat(1,1,size_z)\n",
    "            zz = z_[i].unsqueeze(-1)\n",
    "            zz = zz.repeat(1,1,size_x).T\n",
    "\n",
    "            diff = 1 - torch.sum(torch.mul(xx,zz), 1) # 32,16\n",
    "            softmax_diff = F.softmax(diff*(-alpha),1) #32,16\n",
    "            soft_des_temp = torch.matmul(softmax_diff,z_[i]) # 32,12\n",
    "            if i == 0: descriptor = soft_des_temp\n",
    "            else: descriptor = torch.cat((descriptor,soft_des_temp),1)\n",
    "\n",
    "        return intranorm(descriptor,n_book) # 32,144"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class classifier_(nn.Module):\n",
    "    def __init__(self,n_CLASSES, len_code, n_book,):\n",
    "        super(classifier_,self).__init__()\n",
    "        self.prototypes = nn.Linear(len_code * n_book, n_CLASSES, bias=False)\n",
    "        self.n_book = n_book\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_ = x.split(self.n_book,1)\n",
    "        c_ = (intranorm(self.prototypes.state_dict()['weight'], n_book)*beta).T.split(self.n_book,0)\n",
    "        for i in range(self.n_book):\n",
    "            sub_res = torch.matmul(x_[i], c_[i]).unsqueeze(-1)\n",
    "            if i == 0: res = sub_res\n",
    "            else: res = torch.cat((res,sub_res),2)\n",
    "        \n",
    "        return torch.sum(res, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class features_(nn.Module):\n",
    "    def __init__(self, net1, net2):\n",
    "        super(features_,self).__init__()\n",
    "        \n",
    "        self.net1 = net1\n",
    "        self.net2 = net2\n",
    "        self.gavgp = nn.AdaptiveAvgPool2d(1)\n",
    "        self.linear = nn.Linear(768, len_code*n_book)\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.net1(x) # shape: torch.Size([32, 3, 32,32])>torch.Size([32, 3, 4, 4])\n",
    "        x_branch = self.gavgp(x)\n",
    "        x = self.net2(x) # shape: torch.Size([32, 3, 4, 4])> torch.Size([32, 3, 4, 4])\n",
    "        x = self.gavgp(x)\n",
    "        \n",
    "        x = torch.cat((x,x_branch),1)\n",
    "        \n",
    "        return self.linear(x.view(-1,768))\n",
    "    \n",
    "# x = torch.randn(32, 3, 32, 32, device='cpu')\n",
    "# model = features_(net1, net2)\n",
    "# out = model(x)# model\n",
    "# out.shape, out.split(12,1)[0].shape, model.Z.shape, model.prototypes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class flipGradient_(nn.Module):\n",
    "    def forward(self,x,l=1.0):\n",
    "        positivePath=(x*2).clone().detach().requires_grad_(False)\n",
    "        negativePath=(-x).requires_grad_(True)\n",
    "        return positivePath+negativePath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#models\n",
    "model = features_(net1, net2).to(device)\n",
    "forget_net = features_(net1, net2).to(device)\n",
    "classifier = classifier_(n_CLASSES, len_code, n_book).to(device)\n",
    "discriminator = classifier_(2, len_code, n_book).to(device)\n",
    "softassignment = softassignment_(len_code, n_book, intn_word).to(device)\n",
    "flipGradient = flipGradient_()\n",
    "\n",
    "# optimizer\n",
    "class_optim = optim.Adam(classifier.parameters(),lr=0.002,weight_decay=0.00001,amsgrad=True)\n",
    "model_optim = optim.Adam(model.parameters(),lr=0.0002,weight_decay=0.00001,amsgrad=True)\n",
    "soft_optim = optim.Adam(softassignment.parameters(),lr=0.002,weight_decay=0.00001,amsgrad=True)\n",
    "forg_optim = optim.Adam(forget_net.parameters(),lr=0.002,weight_decay=0.00001,amsgrad=True)\n",
    "disc_optim = optim.Adam(discriminator.parameters(),lr=0.002,weight_decay=0.00001,amsgrad=True)\n",
    "\n",
    "class_optim.zero_grad()\n",
    "model_optim.zero_grad()\n",
    "soft_optim.zero_grad()\n",
    "forg_optim.zero_grad()\n",
    "disc_optim.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9267094882204161bf6b2bfb0bc53e2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=50.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:1\t62.78375577926636\t61.16508674621582\t16.630850315093994\t0.6969852223992348\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5a5c5a0696f4bc19f4a42e80ac623f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e55601f6a5c4d638f29a4f8ee6b0709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.37777540640559476\n",
      "epoch:2\t60.96410942077637\t59.8322811126709\t11.892013430595398\t0.7045582234859467\n",
      "\n",
      "epoch:3\t60.20009422302246\t59.242629528045654\t10.249484360218048\t0.7138472124934196\n",
      "\n",
      "epoch:4\t59.56916093826294\t58.777169704437256\t8.660336136817932\t0.7193053513765335\n",
      "\n",
      "epoch:5\t59.215954303741455\t58.51450252532959\t7.796039164066315\t0.7262647077441216\n",
      "\n",
      "epoch:6\t58.93836975097656\t58.29346418380737\t7.2573288679122925\t0.7300125285983086\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a30d6a1e1e9341a9b80eebc2ef40efaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e64655c674c44c4780f3acdd0888215a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.5448718099297396\n",
      "epoch:7\t58.68287229537964\t58.10357332229614\t6.632027983665466\t0.729028731584549\n",
      "\n",
      "epoch:8\t58.53906774520874\t57.99400568008423\t6.316668689250946\t0.7326974272727966\n",
      "\n",
      "epoch:9\t58.400973320007324\t57.87692642211914\t6.125210285186768\t0.7360685467720032\n",
      "\n",
      "epoch:10\t58.2462944984436\t57.77209949493408\t5.644714444875717\t0.7397869974374771\n",
      "\n",
      "epoch:11\t58.109615325927734\t57.66983366012573\t5.31342950463295\t0.7400111109018326\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae717536e864ae09555271074ef64bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94b4b49216fd4cd2a99bcadd5612a286",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6035012485833238\n",
      "epoch:12\t57.99783277511597\t57.5770525932312\t5.149858981370926\t0.7414542213082314\n",
      "\n",
      "epoch:13\t57.94028043746948\t57.53266382217407\t5.029498755931854\t0.7446908578276634\n",
      "\n",
      "epoch:14\t57.880213260650635\t57.49641036987305\t4.796201109886169\t0.7436771541833878\n",
      "\n",
      "epoch:15\t57.76840162277222\t57.41624975204468\t4.485266000032425\t0.7496164813637733\n",
      "\n",
      "epoch:16\t57.692097663879395\t57.35496807098389\t4.3489925265312195\t0.7427384406328201\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "405eb3cedd5c4f4db7f0439c40b5c187",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87088ac2ab0e4a7992587745ce3e4bb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.5796998266601024\n",
      "epoch:17\t57.63182020187378\t57.31801080703735\t4.113497674465179\t0.7483472302556038\n",
      "\n",
      "epoch:18\t57.54409456253052\t57.24330186843872\t3.991314470767975\t0.7432256415486336\n",
      "\n",
      "epoch:19\t57.50168228149414\t57.234424114227295\t3.6486834287643433\t0.7415945529937744\n",
      "\n",
      "epoch:20\t57.40179395675659\t57.15614032745361\t3.44854599237442\t0.7462454661726952\n",
      "\n",
      "epoch:21\t57.284188747406006\t57.07548666000366\t3.0882182717323303\t0.7461762726306915\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8bd9062517664135977583224f1e6672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b01d066e16fe421081e0e8cc9ffea083",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6480535067431707\n",
      "epoch:22\t57.362011432647705\t57.121007442474365\t3.418461889028549\t0.7439207583665848\n",
      "\n",
      "epoch:23\t57.244842529296875\t57.03714990615845\t3.081064522266388\t0.7391294836997986\n",
      "\n",
      "epoch:24\t57.27329444885254\t57.05602979660034\t3.17857825756073\t0.7443123683333397\n",
      "\n",
      "epoch:25\t57.2189154624939\t57.01193952560425\t3.0780717730522156\t0.742102600634098\n",
      "\n",
      "epoch:26\t57.09269905090332\t56.93277883529663\t2.613275423645973\t0.7451115325093269\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b894decc86943488593c8541ce35cc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ad4ba5ae4274c95a525abc8e4676028",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.676259841238009\n",
      "epoch:27\t57.103707790374756\t56.92757749557495\t2.780221089720726\t0.7428247407078743\n",
      "\n",
      "epoch:28\t57.13498258590698\t56.949249267578125\t2.872847616672516\t0.7456517294049263\n",
      "\n",
      "epoch:29\t57.04120111465454\t56.88070201873779\t2.631280407309532\t0.7441138848662376\n",
      "\n",
      "epoch:30\t56.99705219268799\t56.848122119903564\t2.518518701195717\t0.7445415928959846\n",
      "\n",
      "epoch:31\t56.9514946937561\t56.81932497024536\t2.3514041751623154\t0.7439640313386917\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d97f25b523eb45e9ac29d7ed7eb0ae47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e38ff8dc117490481f995f98c0a457f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6385932859326546\n",
      "epoch:32\t56.99540376663208\t56.84275817871094\t2.5561110377311707\t0.7431143671274185\n",
      "\n",
      "epoch:33\t56.91618204116821\t56.7791314125061\t2.400209069252014\t0.7380931824445724\n",
      "\n",
      "epoch:34\t56.97185277938843\t56.8327693939209\t2.4324663430452347\t0.7402466386556625\n",
      "\n",
      "epoch:35\t57.01722955703735\t56.85948038101196\t2.618986129760742\t0.7351617440581322\n",
      "\n",
      "epoch:36\t56.965492248535156\t56.823612689971924\t2.45974263548851\t0.7402656525373459\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e2d0a61cb2b42c9b929fa9895ed5e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48e9007593f44aaa9ad515a10ded6944",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6516968103772098\n",
      "epoch:37\t56.90149736404419\t56.76744842529297\t2.3821196854114532\t0.734370730817318\n",
      "\n",
      "epoch:38\t56.78257894515991\t56.690874099731445\t1.9734761863946915\t0.7341937869787216\n",
      "\n",
      "epoch:39\t56.86160469055176\t56.74326753616333\t2.241103634238243\t0.733466275036335\n",
      "\n",
      "epoch:40\t56.84748840332031\t56.731242179870605\t2.217312216758728\t0.7338187992572784\n",
      "\n",
      "epoch:41\t56.73908185958862\t56.65461301803589\t1.907302439212799\t0.7360842898488045\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "671e4fce2b1e465285d7b46d88a4a450",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a685fc2676d4de389de034f0752df6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6919166817030709\n",
      "epoch:42\t56.83247137069702\t56.72854042053223\t2.1036475896835327\t0.7307396605610847\n",
      "\n",
      "epoch:43\t56.889057636260986\t56.757164001464844\t2.38005830347538\t0.7338637858629227\n",
      "\n",
      "epoch:44\t56.866347789764404\t56.74502515792847\t2.274666577577591\t0.7340978607535362\n",
      "\n",
      "epoch:45\t56.777050495147705\t56.68388891220093\t1.9999576061964035\t0.7367803975939751\n",
      "\n",
      "epoch:46\t56.652095317840576\t56.59731483459473\t1.621795006096363\t0.7340838611125946\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eadcc5c937bc44bd863af89b998492ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a07f23258448a8a78b450614ae3f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.6765871418680022\n",
      "epoch:47\t56.61803579330444\t56.57230567932129\t1.5367155075073242\t0.7333464249968529\n",
      "\n",
      "epoch:48\t56.63983774185181\t56.585062980651855\t1.6261011883616447\t0.7336803451180458\n",
      "\n",
      "epoch:49\t56.632543087005615\t56.58513021469116\t1.5546146109700203\t0.7323544397950172\n",
      "\n",
      "epoch:50\t56.709335803985596\t56.63968515396118\t1.7696180120110512\t0.7305288016796112\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dummy_target = torch.cat((torch.tensor(1).tile((batchSize,)), torch.tensor(0).tile((batchSize,))),0).to(device)\n",
    "target_ = iter(target)\n",
    "score = 0\n",
    "save = \"\"\n",
    "scoore = ''\n",
    "for epoch in tqdm(range(50)):\n",
    "    m_,n,o,p = 0,0,0,0\n",
    "    model.train()\n",
    "    classifier.train()\n",
    "    softassignment.train()\n",
    "    discriminator.train()\n",
    "    forget_net.train()\n",
    "    for df, batch in enumerate(source):\n",
    "        x, y = batch\n",
    "        if x.shape[0] < batchSize: break\n",
    "        x = torch.tensor(data_augmentation(x)).to(device)\n",
    "        y = y.to(device)\n",
    "        try: \n",
    "            xu = next(target_)\n",
    "            xu = torch.tensor(data_augmentation(xu)).to(device)\n",
    "        except:\n",
    "            target_ = iter(target)\n",
    "            xu = next(target_)\n",
    "            xu = torch.tensor(data_augmentation(xu)).to(device)\n",
    "\n",
    "        # adversarial forgetting\n",
    "        for g in range(1):\n",
    "            input_ = torch.cat((x,xu),0)\n",
    "            z = intranorm(model(input_.permute(0,3,1,2)), n_book)\n",
    "            m = intranorm(forget_net(input_.permute(0,3,1,2)), n_book)\n",
    "            z_ = z * m\n",
    "            \n",
    "            pred = discriminator(z_)\n",
    "            dummy_loss = torch.nn.functional.cross_entropy(pred,dummy_target)\n",
    "        \n",
    "            disc_optim.zero_grad()\n",
    "            forg_optim.zero_grad()\n",
    "            dummy_loss.backward()\n",
    "            disc_optim.step()\n",
    "\n",
    "        class_optim.zero_grad()\n",
    "        model_optim.zero_grad()\n",
    "        soft_optim.zero_grad()\n",
    "        forg_optim.zero_grad()\n",
    "        disc_optim.zero_grad()\n",
    "        \n",
    "        input_ = torch.cat((x,xu),0)\n",
    "        features = intranorm(model(x.permute(0,3,1,2)), n_book)\n",
    "        features_ = intranorm(model(xu.permute(0,3,1,2)), n_book)\n",
    "        z = torch.cat((features,features_),0)\n",
    "        m = intranorm(forget_net(input_.permute(0,3,1,2)), n_book)\n",
    "        z_ = z * m\n",
    "\n",
    "        pred = discriminator(z_)\n",
    "        quanta = softassignment(z_[:batchSize],n_book,alpha)\n",
    "        logits = classifier(z_[:batchSize] *beta)\n",
    "        \n",
    "        entropy_loss = torch.nn.functional.cross_entropy(pred,torch.flip(dummy_target,(0,))) *0.1\n",
    "        mask_regulariser_loss = (m * (1-m)).mean() \n",
    "        \n",
    "        entropy_loss.backward(retain_graph=True)\n",
    "        model_optim.zero_grad()\n",
    "        \n",
    "        cls_loss = torch.nn.functional.cross_entropy(logits,y)\n",
    "\n",
    "        y = torch.eye(numClasses)[y].to(device)\n",
    "        y_ = torch.matmul(y,y.T)\n",
    "        y_ = y_/torch.sum(y_, axis=1, keepdims=True)\n",
    "        hash_loss = NPQLoss(y_,z_[:batchSize], quanta,n_book)  \n",
    "        \n",
    "        final_loss = hash_loss + cls_loss*0.1  + mask_regulariser_loss*0.1\n",
    "        final_loss.backward()\n",
    "        \n",
    "        o += cls_loss.item()\n",
    "        m_ += final_loss.item()\n",
    "        n += hash_loss.item()\n",
    "        p += entropy_loss.item()\n",
    "#         print(final_loss.item())\n",
    "        \n",
    "        model_optim.step()\n",
    "        soft_optim.step()\n",
    "        class_optim.step()\n",
    "        forg_optim.step()\n",
    "\n",
    "    print(f\"epoch:{epoch+1}\\t{m_}\\t{n}\\t{o}\\t{p}\\n\")\n",
    "    save += f\"{m_/10}\\t{n/10}\\t{o/10}\\t{p/10}\\n\"\n",
    "    with open(\"analysis.txt\", \"w\") as f:\n",
    "        f.write(save)\n",
    "#     continue\n",
    "    \n",
    "    if epoch % 5 == 0:\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            forget_net.eval()\n",
    "            \n",
    "            for r, i in tqdm(enumerate(gallery)):\n",
    "                dfg = intranorm(model(i.to(device).permute(0,3,1,2)),n_book) * intranorm(forget_net(i.to(device).permute(0,3,1,2)), n_book)\n",
    "                if r == 0: \n",
    "                    dummy = dfg\n",
    "                else: \n",
    "                    dummy = torch.cat((dummy, dfg), 0)\n",
    "\n",
    "            for r, i in tqdm(enumerate(query)):\n",
    "                dfg = intranorm(model(i.to(device).permute(0,3,1,2)),n_book) * intranorm(forget_net(i.to(device).permute(0,3,1,2)), n_book)\n",
    "                if r == 0: \n",
    "                    query_x = dfg\n",
    "                else: \n",
    "                    query_x = torch.cat((query_x, dfg), 0)\n",
    "\n",
    "\n",
    "        dummy = Indexing_(softassignment.Z.state_dict()['weight'].cpu(), dummy.cpu(), n_book)\n",
    "        gallery_x = dummy.numpy().astype(int)\n",
    "        quantizedDist = pqDist(intranorm(softassignment.Z.state_dict()['weight'].cpu(), n_book), n_book,gallery_x, query_x.cpu().numpy()).T\n",
    "        Rank = np.argsort(quantizedDist, axis=0)\n",
    "        mean_average_precision=cat_apcal(similarity,Rank,54000)\n",
    "        scoore += f\"{mean_average_precision}\\n\"\n",
    "        if mean_average_precision > score:\n",
    "            score = mean_average_precision\n",
    "            stateToBeSaved={\n",
    "                'modelStateDict': [model.state_dict(),classifier.state_dict(), softassignment.state_dict(), forget_net.state_dict()],\n",
    "                'score': mean_average_precision,}\n",
    "            torch.save(stateToBeSaved,f\"/home/hemant/mod2_hemant.pth\")\n",
    "        print(mean_average_precision)\n",
    "        with open(\"score.txt\", \"w\") as f:\n",
    "            f.write(save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# THE END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne plots\n",
    "\n",
    "from sklearn.manifold import TSNE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def tsne_plot(labelled_feature,unlabelled_features,labelled_classes):\n",
    "  \n",
    "  target_classes = np.argmax(labelled_classes, axis = 1)\n",
    "\n",
    "  target_ids=range(len(labelled_classes))\n",
    "\n",
    "  tsne = TSNE(n_components=2)\n",
    "  colors = ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'w', 'orange', 'purple']\n",
    "  plt.figure(figsize=(6, 5))\n",
    "  labelled_tsne=tsne.fit_transform(labelled_feature)\n",
    "  unlabelled_tsne=tsne.fit_transform(unlabelled_features)\n",
    "  for i, c, label in zip(target_ids, colors,target_classes ):\n",
    "      plt.scatter(labelled_tsne[target_classes == i, 0], labelled_tsne[target_classes == i, 1], c=c, label=i)\n",
    "\n",
    "  unlabelled_tsne=tsne.fit_transform(unlabelled_features)\n",
    "  plt.scatter(x=unlabelled_tsne[:,0],y=unlabelled_tsne[:,1],c='gray',label='Unlabelled Data')\n",
    "\n",
    "\n",
    "  plt.legend()\n",
    "  plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'source_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-3f3fcc89f41d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtsne_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgallery_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumClasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'source_x' is not defined"
     ]
    }
   ],
   "source": [
    "tsne_plot(source_x.cpu().numpy(),gallery_x.cpu().numpy(),torch.eye(numClasses)[y_].cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabelled_tsne=tsne.fit_transform(unlabelled_features)\n",
    "  plt.scatter(x=unlabelled_tsne[:,0],y=unlabelled_tsne[:,1],c='gray',label='Unlabelled Data')\n",
    "\n",
    "\n",
    "  plt.legend()\n",
    "  plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for r, i in tqdm(enumerate(gallery)):\n",
    "        dfg = intranorm(model(i.to(device).permute(0,3,1,2)),n_book).cpu() \n",
    "        if r == 0: \n",
    "            gallery_x = dfg\n",
    "        else: \n",
    "            gallery_x = torch.cat((gallery_x, dfg), 0)\n",
    "    \n",
    "    for r, batch in enumerate(source):\n",
    "        i, y = batch\n",
    "        dfg = intranorm(model(i.to(device).permute(0,3,1,2)),n_book) \n",
    "        if r == 0: \n",
    "            source_x = dfg\n",
    "            y_ = y\n",
    "        else: \n",
    "            source_x = torch.cat((source_x, dfg), 0)\n",
    "            y_ = torch.cat((y_,y),0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
